{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸ”§ SETUP - Add src to Python Path\n",
    "# ================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path so 'core' module can be found\n",
    "project_root = os.getcwd()\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"âœ… Added to Python path: {src_path}\")\n",
    "else:\n",
    "    print(f\"âœ… Already in path: {src_path}\")\n",
    "\n",
    "# Verify\n",
    "print(f\"ğŸ“‚ Working directory: {project_root}\")\n",
    "print(f\"ğŸ” Python will search for modules in: {src_path}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Already in path: d:\\Dev\\trading-bot\\src\n",
      "ğŸ“‚ Working directory: d:\\Dev\\trading-bot\n",
      "ğŸ” Python will search for modules in: d:\\Dev\\trading-bot\\src\n",
      "==================================================\n",
      "ğŸ§ª PROGRESSIVE TEST - Training on 100 candles\n",
      "======================================================================\n",
      "\n",
      "â±ï¸  Starting progressive training...\n",
      "   Time range: 2023-04-03 13:45:00 to 2023-06-01 04:00:00\n",
      "   This will process each candle individually\n",
      "\n",
      "ğŸ“ TRAINING MODEL\n",
      "==============================\n",
      "\n",
      "ğŸ“‹ Validating training files...\n",
      "   âœ… Main file (15m): d:\\Dev\\trading-bot\\data\\BTCUSDT-15m.json\n",
      "   âœ… Parquet file: d:\\Dev\\trading-bot\\data\\levels_cache\\BTCUSDT-15m-levels.parquet.checkpoint\n",
      "\n",
      "ğŸ“Š Validating level timeframes: ['W', 'D', '1h', '15m']\n",
      "   âœ… W: d:\\Dev\\trading-bot\\data\\BTCUSDT-W.json\n",
      "   âœ… D: d:\\Dev\\trading-bot\\data\\BTCUSDT-D.json\n",
      "   âœ… 1h: d:\\Dev\\trading-bot\\data\\BTCUSDT-1h.json\n",
      "   âœ… 15m: d:\\Dev\\trading-bot\\data\\BTCUSDT-15m.json\n",
      "\n",
      "âœ… All 4 level timeframe files validated!\n",
      "   Level timeframes: ['W', 'D', '1h', '15m']\n",
      "\n",
      "ğŸ“¦ Loading precomputed features from parquet...\n",
      "   âœ… Loaded 5,902 candles from precomputed parquet\n",
      "\n",
      "ğŸ“‚ Loading level timeframe data...\n",
      "\n",
      "ğŸ“‚ PRE-LOADING ALL DATA FILES (one-time operation)...\n",
      "   Loading W... âœ… 288 candles\n",
      "   Loading D... âœ… 2,021 candles\n",
      "   Loading 1h... âœ… 48,461 candles\n",
      "   Loading 15m... âœ… 87,891 candles\n",
      "âœ… All data files loaded into memory!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸš€ PREPARING TRAINING DATA (OPTIMIZED)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ˆ Step 1/4: Calculating TA features for FULL dataset...\n",
      "   Using 5,902 candles (includes all historical data)\n",
      "ğŸ”„ Calculating TA features (ta_15m_20230403_20230604_5902)...\n",
      "âœ… TA features calculated and cached: 11 features (0.00s)\n",
      "   âœ… TA features calculated in 0.00s (11 features)\n",
      "\n",
      "ğŸ“… Step 2/4: Filtering to training time range...\n",
      "   â° Start time: 2023-04-03 13:45:00\n",
      "   â° End time: 2023-06-01 04:00:00\n",
      "   âœ… Training range: 5626 candles (2023-04-03 13:45:00 to 2023-06-01 04:00:00)\n",
      "   âœ… TA features filtered: 5626 samples\n",
      "\n",
      "ğŸ“Š Step 3/4: Pre-processing levels for 5626 candles...\n",
      "   âœ… Levels pre-processed in 2.42s\n",
      "\n",
      "ï¿½ Step 2/4: Calculating TA features for entire dataset...\n",
      "ğŸ”„ Calculating TA features (ta_15m_20230403_20230601_5626)...\n",
      "âœ… TA features calculated and cached: 11 features (0.00s)\n",
      "   âœ… TA features calculated in 0.00s (11 features)\n",
      "\n",
      "ğŸ¯ Step 3/4: Calculating level features per candle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Level features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5626/5626 [00:00<00:00, 12254.30it/s]\n",
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x000001894C077970>>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 641, in _next_wrapper\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 557, in _handle_exception\n",
      "    return fn()\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 641, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\data.py\", line 1280, in next\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Level features calculated in 0.48s (27 features)\n",
      "\n",
      "ğŸ’¾ Step 4/4: Adding memory features...\n",
      "   âœ… Memory features added in 0.000s (10 features)\n",
      "\n",
      "ğŸ”— Combining all feature groups...\n",
      "   âœ… Features combined in 0.001s\n",
      "\n",
      "âœ… Features ready: 5626 samples, 48 features\n",
      "   TA: 11, Level: 27, Memory: 10\n",
      "ğŸ·ï¸  Generating trading labels...\n",
      "ğŸ·ï¸  Generating labels based on price movements...\n",
      "   BUY signals: 49 (0.9%)\n",
      "   SELL signals: 165 (2.9%)\n",
      "   HOLD signals: 5412 (96.2%)\n",
      "âœ… Training data ready: 5626 samples, 48 features\n",
      "ğŸ“Š Label distribution:\n",
      "   hold: 5412 (96.2%)\n",
      "   sell: 165 (2.9%)\n",
      "   buy: 49 (0.9%)\n",
      "\n",
      "======================================================================\n",
      "âœ… TRAINING DATA PREPARATION COMPLETE\n",
      "======================================================================\n",
      "â±ï¸  Total time: 2.92 seconds (0.05 minutes)\n",
      "ğŸ“Š Total samples: 5,626\n",
      "ğŸ“Š Total features: 48\n",
      "âš¡ Average time per sample: 0.0005 seconds\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¥ Training with 4500 samples, 48 features\n",
      "ğŸ–¥ï¸  GPU Detection: âœ… Available\n",
      "   ğŸš€ Training with GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    input_data(**self.kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 633, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 932, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1070, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\data.py\", line 1218, in dispatch_meta_backend\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\xgboost\\data.py\", line 1159, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     âœ… GPU Training Complete: 2.66s | Accuracy: 98.5%\n",
      "\n",
      "âœ… TRAINING COMPLETE!\n",
      "   Model: XGBoost-GPU\n",
      "   Test Accuracy: 98.5%\n",
      "\n",
      "ğŸ” Top 10 Features:\n",
      "     support_resistance_ratio: 0.096\n",
      "     levels_within_5.0pct: 0.073\n",
      "     time: 0.070\n",
      "     bb_upper: 0.067\n",
      "     num_levels: 0.061\n",
      "     resistance_count: 0.060\n",
      "     volume_ma20: 0.057\n",
      "     levels_within_1.0pct: 0.055\n",
      "     levels_within_2.0pct: 0.053\n",
      "     support_count: 0.046\n",
      "ğŸ’¾ Model saved to: src/models/simple_trading_model.joblib\n",
      "\n",
      "ğŸ‰ TEST TRAINING SUCCESS!\n",
      "   Model Type: XGBoost-GPU\n",
      "   Accuracy: 98.5%\n",
      "   Features: 48\n",
      "   Classes: ['buy', 'hold', 'sell']\n",
      "\n",
      "âœ… Progressive approach is working correctly!\n",
      "   You can now train on full dataset\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path so 'core' module can be found\n",
    "project_root = os.getcwd()\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"âœ… Added to Python path: {src_path}\")\n",
    "else:\n",
    "    print(f\"âœ… Already in path: {src_path}\")\n",
    "\n",
    "# Verify\n",
    "print(f\"ğŸ“‚ Working directory: {project_root}\")\n",
    "print(f\"ğŸ” Python will search for modules in: {src_path}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ================================================\n",
    "# ğŸ§ª TEST PROGRESSIVE TRAINING (100 candles only)\n",
    "# ================================================\n",
    "\n",
    "print(\"ğŸ§ª PROGRESSIVE TEST - Training on 100 candles\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from src.training.model_trainer import SimpleModelTrainer\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Training files\n",
    "training_files = {\n",
    "    'M': os.path.join(data_folder, 'BTCUSDT-M.json'),\n",
    "    'W': os.path.join(data_folder, 'BTCUSDT-W.json'),\n",
    "    'D': os.path.join(data_folder, 'BTCUSDT-D.json'),\n",
    "    '1h': os.path.join(data_folder, 'BTCUSDT-1h.json'),\n",
    "    '15m': os.path.join(data_folder, 'BTCUSDT-15m.json'),\n",
    "    'parquet_path': os.path.join(data_folder, 'levels_cache', 'BTCUSDT-15m-levels.parquet.checkpoint'),\n",
    "}\n",
    "\n",
    "# Initialize trainer\n",
    "test_trainer = SimpleModelTrainer()\n",
    "\n",
    "start_time = pd.Timestamp('2023-04-03 13:45:00')\n",
    "end_time = pd.Timestamp('2023-06-01 04:00:00')\n",
    "\"\"\" start_time = pd.Timestamp('2023-04-10 00:00:00')\n",
    "end_time = pd.Timestamp('2023-05-15 23:59:59') \"\"\"\n",
    "# Configure training with time range filter\n",
    "test_trainer.configure_training(\n",
    "    profit_threshold=3.0,\n",
    "    loss_threshold=-2.0,\n",
    "    lookforward_periods=[5, 10, 20],\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    ")\n",
    "\n",
    "print(f\"\\nâ±ï¸  Starting progressive training...\")\n",
    "print(f\"   Time range: {start_time} to {end_time}\")\n",
    "print(f\"   This will process each candle individually\\n\")\n",
    "\n",
    "# Train the model\n",
    "success = test_trainer.train_model(\n",
    "    training_files=training_files,\n",
    "    level_timeframes=['W', 'D', '1h', '15m']\n",
    ")\n",
    "\n",
    "if success:\n",
    "    info = test_trainer.get_model_info()\n",
    "    print(f\"\\nğŸ‰ TEST TRAINING SUCCESS!\")\n",
    "    print(f\"   Model Type: {info['model_type']}\")\n",
    "    print(f\"   Accuracy: {info['accuracy']:.1%}\")\n",
    "    print(f\"   Features: {info['features']}\")\n",
    "    print(f\"   Classes: {info['classes']}\")\n",
    "    print(f\"\\nâœ… Progressive approach is working correctly!\")\n",
    "    print(f\"   You can now train on full dataset\")\n",
    "else:\n",
    "    print(\"âŒ Test training failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1114f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# ğŸš€ VECTORBT BACKTESTING - Replacing Manual Simulation\n",
    "# ================================================\n",
    "\n",
    "print(\"ğŸš€ VECTORBT BACKTESTING MODE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from src.backtesting.vectorbt_engine import VectorBTBacktester\n",
    "from src.training.model_trainer import SimpleModelTrainer\n",
    "\n",
    "# Load model from file (independent from training cell)\n",
    "print(\"ğŸ“ Loading model from file...\")\n",
    "simulation_trainer = SimpleModelTrainer()\n",
    "\n",
    "try:\n",
    "    success = simulation_trainer.load_model()\n",
    "    if not success:\n",
    "        print(\"âŒ Failed to load model from file\")\n",
    "        print(\"   Make sure you've trained the model first (run Cell 2)\")\n",
    "        simulation_trainer = None\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    simulation_trainer = None\n",
    "\n",
    "if simulation_trainer is not None and simulation_trainer.is_trained:\n",
    "    print(\"âœ… Model loaded successfully!\")\n",
    "    \n",
    "    # Display model info\n",
    "    info = simulation_trainer.get_model_info()\n",
    "    print(f\"   Model: {info['model_type']} | Accuracy: {info['accuracy']:.1%} | Features: {info['features']}\")\n",
    "    \n",
    "    # Configuration\n",
    "    test_symbol = 'BTCUSDT'\n",
    "    MAX_CANDLES = 100  # REDUCED for progressive backtesting (each candle recalculates levels!)\n",
    "    test_data_folder = 'data_test'\n",
    "    \n",
    "    # Threshold settings\n",
    "    buy_threshold = 0.10\n",
    "    sell_threshold = 0.10\n",
    "    \n",
    "    # VectorBT settings\n",
    "    initial_cash = 10000.0\n",
    "    commission = 0.001  # 0.1%\n",
    "    slippage = 0.0005   # 0.05%\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Symbol: {test_symbol}\")\n",
    "    print(f\"ğŸ“Š Backtesting: {MAX_CANDLES} candles (PROGRESSIVE - no data leakage)\")\n",
    "    print(f\"âš™ï¸  Thresholds: BUYâ‰¥{buy_threshold:.0%}, SELLâ‰¥{sell_threshold:.0%}\")\n",
    "    print(f\"ğŸ’° Initial Cash: ${initial_cash:,.2f}\")\n",
    "    print(f\"ğŸ’¸ Commission: {commission:.2%} | Slippage: {slippage:.2%}\\n\")\n",
    "    \n",
    "    # Helper function to load JSON data\n",
    "    def load_json_data(filepath):\n",
    "        \"\"\"Load OHLCV data from JSON file\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract candles array\n",
    "        candles = data.get('candles', [])\n",
    "        if not candles:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(candles)\n",
    "        \n",
    "        # Convert time (Unix timestamp) to datetime\n",
    "        df['datetime'] = pd.to_datetime(df['time'], unit='s')\n",
    "        df = df.drop('time', axis=1)  # Remove Unix timestamp column\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Get file paths\n",
    "    test_files = {\n",
    "        '15m': os.path.join(test_data_folder, f'{test_symbol}-15m.json'),\n",
    "        '1h': os.path.join(test_data_folder, f'{test_symbol}-1h.json'),\n",
    "        'D': os.path.join(test_data_folder, f'{test_symbol}-D.json'),\n",
    "        'W': os.path.join(test_data_folder, f'{test_symbol}-W.json'),\n",
    "        'M': os.path.join(test_data_folder, f'{test_symbol}-M.json'),\n",
    "    }\n",
    "    \n",
    "    # Check if 15m file exists\n",
    "    if not os.path.exists(test_files['15m']):\n",
    "        print(f\"âŒ No 15m data file found for {test_symbol}\")\n",
    "    else:\n",
    "        # Load 15m data (primary trading timeframe)\n",
    "        print(\"ğŸ“Š Loading 15m data...\")\n",
    "        test_data = load_json_data(test_files['15m'])\n",
    "        \n",
    "        if test_data is None:\n",
    "            print(\"âŒ Could not load test data\")\n",
    "        else:\n",
    "            print(f\"âœ… Loaded {len(test_data)} total candles\")\n",
    "            print(f\"ğŸ“… Range: {test_data['datetime'].min()} to {test_data['datetime'].max()}\")\n",
    "            \n",
    "            # Get the last MAX_CANDLES for backtesting\n",
    "            if len(test_data) < MAX_CANDLES:\n",
    "                print(f\"âš ï¸  Only {len(test_data)} candles available, using all\")\n",
    "            else:\n",
    "                test_data = test_data.tail(MAX_CANDLES).reset_index(drop=True)\n",
    "            \n",
    "            print(f\"\\nğŸ¬ Starting progressive backtest with {len(test_data)} candles...\")\n",
    "            print(f\"ğŸ“ Backtest period: {test_data['datetime'].min()} to {test_data['datetime'].max()}\")\n",
    "            \n",
    "            # Load all timeframe data as DataFrames (needed for level extraction)\n",
    "            print(\"\\nğŸ“‚ Loading multi-timeframe data for level extraction...\")\n",
    "            data_dfs = {}\n",
    "            \n",
    "            for tf, filepath in test_files.items():\n",
    "                if tf == '15m':\n",
    "                    continue  # Already loaded\n",
    "                if os.path.exists(filepath):\n",
    "                    print(f\"   Loading {tf}...\")\n",
    "                    df = load_json_data(filepath)\n",
    "                    if df is not None:\n",
    "                        data_dfs[tf] = df\n",
    "                else:\n",
    "                    print(f\"   âš ï¸  {tf} file not found, skipping\")\n",
    "            \n",
    "            print(f\"âœ… Loaded {len(data_dfs)} additional timeframes for levels\\n\")\n",
    "            \n",
    "            # Set datetime as index (required for VectorBT)\n",
    "            test_data_indexed = test_data.set_index('datetime')\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 55)\n",
    "            print(\"ğŸš€ VECTORBT PROGRESSIVE BACKTEST STARTING...\")\n",
    "            print(\"=\" * 55)\n",
    "            print(\"âš ï¸  Note: Progressive mode recalculates levels for EACH candle\")\n",
    "            print(\"   This is SLOW but prevents data leakage (realistic trading)\")\n",
    "            print(\"   Progress bar will show each candle being processed\\n\")\n",
    "            \n",
    "            # Initialize VectorBT backtester\n",
    "            backtester = VectorBTBacktester(\n",
    "                trainer=simulation_trainer,\n",
    "                initial_cash=initial_cash,\n",
    "                commission=commission,\n",
    "                slippage=slippage\n",
    "            )\n",
    "            \n",
    "            # Generate signals progressively (includes level extraction per candle)\n",
    "            signals_df = backtester.generate_signals(\n",
    "                data=test_data_indexed,\n",
    "                data_dfs=data_dfs,\n",
    "                buy_threshold=buy_threshold,\n",
    "                sell_threshold=sell_threshold,\n",
    "                timeframe='15m'\n",
    "            )\n",
    "            \n",
    "            # Run backtest (THIS IS FAST - vectorized)\n",
    "            print(\"\\nğŸš€ Running backtest...\")\n",
    "            portfolio = backtester.run_backtest(signals_df=signals_df, freq='15T')\n",
    "            \n",
    "            # Display performance summary\n",
    "            backtester.print_performance_summary()\n",
    "            \n",
    "            # Get trade analysis\n",
    "            trades_df = backtester.get_trade_analysis()\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 55)\n",
    "            print(\"ğŸ“‹ TRADE ANALYSIS\")\n",
    "            print(\"=\" * 55)\n",
    "            \n",
    "            if len(trades_df) > 0:\n",
    "                print(f\"\\nğŸ“Š Total Trades: {len(trades_df)}\")\n",
    "                \n",
    "                winning_trades = trades_df[trades_df['PnL'] > 0]\n",
    "                losing_trades = trades_df[trades_df['PnL'] < 0]\n",
    "                \n",
    "                print(f\"âœ… Winning: {len(winning_trades)} ({len(winning_trades)/len(trades_df)*100:.1f}%)\")\n",
    "                print(f\"âŒ Losing:  {len(losing_trades)} ({len(losing_trades)/len(trades_df)*100:.1f}%)\")\n",
    "                \n",
    "                if len(winning_trades) > 0:\n",
    "                    print(f\"\\nğŸ’š Average Win: ${winning_trades['PnL'].mean():.2f}\")\n",
    "                    print(f\"ğŸ’š Largest Win: ${winning_trades['PnL'].max():.2f}\")\n",
    "                \n",
    "                if len(losing_trades) > 0:\n",
    "                    print(f\"ğŸ’” Average Loss: ${losing_trades['PnL'].mean():.2f}\")\n",
    "                    print(f\"ğŸ’” Largest Loss: ${losing_trades['PnL'].min():.2f}\")\n",
    "                \n",
    "                # Show sample trades\n",
    "                print(f\"\\nğŸ“‹ Sample Trades (first 10):\")\n",
    "                print(trades_df.head(10))\n",
    "            else:\n",
    "                print(\"âš ï¸  No trades executed during backtest period\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 55)\n",
    "            print(\"âœ… VECTORBT BACKTEST COMPLETE!\")\n",
    "            print(\"=\" * 55)\n",
    "            \n",
    "            # Signal distribution\n",
    "            signal_counts = signals_df['signal'].value_counts()\n",
    "            print(f\"\\nğŸ¯ SIGNAL DISTRIBUTION:\")\n",
    "            for signal in ['BUY', 'SELL', 'HOLD']:\n",
    "                count = signal_counts.get(signal, 0)\n",
    "                pct = (count / len(signals_df) * 100) if len(signals_df) > 0 else 0\n",
    "                print(f\"   {signal}: {count} ({pct:.1f}%)\")\n",
    "            \n",
    "            # Show trading signals (non-HOLD)\n",
    "            trade_signals = signals_df[signals_df['signal'] != 'HOLD']\n",
    "            print(f\"\\nğŸ“‹ TRADING SIGNALS ({len(trade_signals)} total):\")\n",
    "            if len(trade_signals) > 0:\n",
    "                for timestamp, row in trade_signals.head(20).iterrows():\n",
    "                    emoji = \"ğŸŸ¢\" if row['signal'] == 'BUY' else \"ğŸ”´\"\n",
    "                    print(f\"   {emoji} {timestamp} | \" +\n",
    "                          f\"{row['signal']:4s} @ ${row['close']:8.2f} | \" +\n",
    "                          f\"Conf: {row['confidence']:5.1%}\")\n",
    "            else:\n",
    "                print(\"   No trading signals generated\")\n",
    "            \n",
    "            print(\"\\nâœ… Progressive backtest complete!\")\n",
    "            print(\"   â„¹ï¸  Each candle was processed independently with levels extracted\")\n",
    "            print(\"      at that point in time (no future data leakage)\")\n",
    "            \n",
    "            # ================================================\n",
    "            # ğŸ“Š OPTIONAL: GENERATE INTERACTIVE PLOTS\n",
    "            # ================================================\n",
    "            \n",
    "            try:\n",
    "                print(\"\\nğŸ“Š Generating interactive plots...\")\n",
    "                # Use static plots (no anywidget dependency)\n",
    "                backtester.plot_results(use_widgets=False)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Could not generate plots: {e}\")\n",
    "                if \"anywidget\" in str(e):\n",
    "                    print(\"   â„¹ï¸  anywidget not installed\")\n",
    "                    print(\"   Solution: Restart the kernel (Kernel â†’ Restart)\")\n",
    "                print(\"   Use VectorBT_Backtest.ipynb for full visualization\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No model available\")\n",
    "    print(\"   Please run Cell 2 first to train the model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
