{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2164cd35",
   "metadata": {},
   "source": [
    "# üöÄ VectorBT Backtesting - Cryptocurrency Trading Bot\n",
    "\n",
    "This notebook demonstrates the **VectorBT backtesting engine** replacing the manual candle-by-candle simulation approach.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ Vectorized signal generation from XGBoost predictions\n",
    "- ‚úÖ High-performance backtesting with realistic commissions/slippage\n",
    "- ‚úÖ Comprehensive performance metrics (Sharpe, drawdown, win rate, etc.)\n",
    "- ‚úÖ Interactive visualizations (equity curve, trades, drawdown)\n",
    "- ‚úÖ Trade-by-trade analysis\n",
    "- ‚úÖ Export results to CSV\n",
    "\n",
    "## Advantages over Manual Simulation:\n",
    "- **10-100x faster** execution\n",
    "- More realistic trade execution\n",
    "- Professional-grade metrics\n",
    "- Better visualization capabilities\n",
    "- Easier parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8ae00",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b756903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project root: d:\\Dev\\trading-bot\n",
      "‚úÖ Added to path: d:\\Dev\\trading-bot\\src\n",
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.getcwd()\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"‚úÖ Project root: {project_root}\")\n",
    "print(f\"‚úÖ Added to path: {src_path}\")\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import vectorbt as vbt\n",
    "\n",
    "# Trading bot imports\n",
    "from src.training.model_trainer import SimpleModelTrainer\n",
    "from src.backtesting.vectorbt_engine import VectorBTBacktester\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7207e",
   "metadata": {},
   "source": [
    "## üéØ Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf538671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading trained model from file...\n",
      "============================================================\n",
      "‚úÖ Level extractor initialized with timeframe caching\n",
      "‚úÖ Level extractor initialized with timeframe caching\n",
      "üìÅ Loading model from: src/models/simple_trading_model.joblib\n",
      "‚úÖ Model loaded: XGBoost-GPU (Accuracy: 96.8%)\n",
      "‚úÖ Model loaded successfully!\n",
      "\n",
      "üìä Model Information:\n",
      "   Type: XGBoost-GPU\n",
      "   Accuracy: 96.81%\n",
      "   Features: 51\n",
      "   Training Date: Unknown\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÅ Loading trained model from file...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create trainer instance\n",
    "trainer = SimpleModelTrainer()\n",
    "\n",
    "# Load model\n",
    "success = trainer.load_model()\n",
    "\n",
    "if not success or not trainer.is_trained:\n",
    "    print(\"‚ùå Failed to load model!\")\n",
    "    print(\"   Please run the training cell in Simple_Model_Debug.ipynb first\")\n",
    "    raise ValueError(\"No trained model available\")\n",
    "\n",
    "# Display model info\n",
    "info = trainer.get_model_info()\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"\\nüìä Model Information:\")\n",
    "print(f\"   Type: {info['model_type']}\")\n",
    "print(f\"   Accuracy: {info['accuracy']:.2%}\")\n",
    "print(f\"   Features: {info['features']}\")\n",
    "print(f\"   Training Date: {info.get('training_date', 'Unknown')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210790f",
   "metadata": {},
   "source": [
    "## üìä Configure Backtest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c64ed5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  BACKTEST CONFIGURATION\n",
      "============================================================\n",
      "Symbol:           BTCUSDT\n",
      "Data Folder:      data_test\n",
      "Max Candles:      1000\n",
      "\n",
      "üìà Trading Thresholds:\n",
      "BUY Threshold:    10.0%\n",
      "SELL Threshold:   10.0%\n",
      "\n",
      "üí∞ VectorBT Settings:\n",
      "Initial Cash:     $100,000.00\n",
      "Commission:       0.10%\n",
      "Slippage:         0.05%\n",
      "Frequency:        15T\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Backtest Configuration\n",
    "SYMBOL = 'BTCUSDT'\n",
    "DATA_FOLDER = 'data_test'\n",
    "MAX_CANDLES = 1000  # Use more candles for realistic backtest (was 250 in simulation)\n",
    "\n",
    "# Trading Parameters\n",
    "BUY_THRESHOLD = 0.10   # 10% minimum confidence for BUY\n",
    "SELL_THRESHOLD = 0.10  # 10% minimum confidence for SELL\n",
    "\n",
    "# VectorBT Parameters\n",
    "INITIAL_CASH = 100000.0  # Starting capital: $10,000\n",
    "COMMISSION = 0.001      # 0.1% commission per trade (typical crypto exchange)\n",
    "SLIPPAGE = 0.0005       # 0.05% slippage\n",
    "FREQ = '15T'            # 15-minute candles\n",
    "\n",
    "print(\"‚öôÔ∏è  BACKTEST CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Symbol:           {SYMBOL}\")\n",
    "print(f\"Data Folder:      {DATA_FOLDER}\")\n",
    "print(f\"Max Candles:      {MAX_CANDLES}\")\n",
    "print(f\"\\nüìà Trading Thresholds:\")\n",
    "print(f\"BUY Threshold:    {BUY_THRESHOLD:.1%}\")\n",
    "print(f\"SELL Threshold:   {SELL_THRESHOLD:.1%}\")\n",
    "print(f\"\\nüí∞ VectorBT Settings:\")\n",
    "print(f\"Initial Cash:     ${INITIAL_CASH:,.2f}\")\n",
    "print(f\"Commission:       {COMMISSION:.2%}\")\n",
    "print(f\"Slippage:         {SLIPPAGE:.2%}\")\n",
    "print(f\"Frequency:        {FREQ}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c6830",
   "metadata": {},
   "source": [
    "## üé® Configure Feature System (New!)\n",
    "\n",
    "The new FeatureManager optimizes feature calculation:\n",
    "- **Group 1 (Level Features)**: Updated once per day, cached\n",
    "- **Group 2 (TA Features)**: Pre-calculated once for entire dataset (avoids NaN/null)\n",
    "\n",
    "You can customize which middlewares to use per timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9284d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom middleware configuration created:\n",
      "   15m: ['zigzag_middleware', 'levels_middleware']\n",
      "   1h: ['zigzag_middleware', 'channels_middleware', 'levels_middleware']\n",
      "   D: ['zigzag_middleware', 'channels_middleware', 'levels_middleware', 'volume_profile_middleware']\n",
      "   W: ['zigzag_middleware', 'levels_middleware', 'volume_profile_middleware']\n",
      "   M: ['zigzag_middleware', 'levels_middleware', 'volume_profile_middleware']\n"
     ]
    }
   ],
   "source": [
    "# Import middleware functions\n",
    "from src.ta.middlewares.zigzag import zigzag_middleware\n",
    "from src.ta.middlewares.volume_profile import volume_profile_middleware\n",
    "from src.ta.middlewares.channels import channels_middleware\n",
    "from src.ta.middlewares.levels import levels_middleware\n",
    "\n",
    "# Custom middleware configuration per timeframe\n",
    "custom_middleware_config = {\n",
    "    '15m': [zigzag_middleware, levels_middleware],  # Lightweight for 15m\n",
    "    '1h': [zigzag_middleware, channels_middleware, levels_middleware],\n",
    "    'D': [zigzag_middleware, channels_middleware, levels_middleware, volume_profile_middleware],\n",
    "    'W': [zigzag_middleware, levels_middleware, volume_profile_middleware],\n",
    "    'M': [zigzag_middleware, levels_middleware, volume_profile_middleware]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Custom middleware configuration created:\")\n",
    "for tf, middlewares in custom_middleware_config.items():\n",
    "    print(f\"   {tf}: {[m.__name__ for m in middlewares]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217886cc",
   "metadata": {},
   "source": [
    "## üì• Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3136496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading test data...\n",
      "============================================================\n",
      "‚úÖ Level extractor initialized with timeframe caching\n",
      "‚úÖ Level extractor initialized with timeframe caching\n",
      "‚úÖ Found 5 timeframe files:\n",
      "   15m: data_test\\BTCUSDT-15m.json\n",
      "    1h: data_test\\BTCUSDT-1h.json\n",
      "     D: data_test\\BTCUSDT-D.json\n",
      "     W: data_test\\BTCUSDT-W.json\n",
      "     M: data_test\\BTCUSDT-M.json\n",
      "\n",
      "‚úÖ Loaded 87891 total candles\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Dev\\trading-bot\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\Dev\\trading-bot\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Dev\\trading-bot\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load test data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m total candles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìÖ Date Range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Get last N candles for backtest\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_data) \u001b[38;5;241m>\u001b[39m MAX_CANDLES:\n",
      "File \u001b[1;32md:\\Dev\\trading-bot\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Dev\\trading-bot\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "from src.prediction.predictor import SimpleModelPredictor\n",
    "import json\n",
    "\n",
    "print(\"üì• Loading test data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create predictor to access data loading utilities\n",
    "predictor = SimpleModelPredictor(trainer)\n",
    "\n",
    "# Get data files for symbol\n",
    "test_files = predictor._get_symbol_files(SYMBOL, DATA_FOLDER)\n",
    "\n",
    "if not test_files:\n",
    "    raise ValueError(f\"No data files found for {SYMBOL} in {DATA_FOLDER}\")\n",
    "\n",
    "print(f\"‚úÖ Found {len(test_files)} timeframe files:\")\n",
    "for tf, path in test_files.items():\n",
    "    print(f\"   {tf:>3s}: {path}\")\n",
    "\n",
    "# Load 15m data (primary timeframe)\n",
    "if '15m' not in test_files:\n",
    "    raise ValueError(f\"No 15m data found for {SYMBOL}\")\n",
    "\n",
    "test_data = predictor._load_json_data(test_files['15m'])\n",
    "\n",
    "if test_data is None:\n",
    "    raise ValueError(\"Failed to load test data\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(test_data)} total candles\")\n",
    "print(f\"üìÖ Date Range: {test_data['datetime'].min()} to {test_data['datetime'].max()}\")\n",
    "\n",
    "# Get last N candles for backtest\n",
    "if len(test_data) > MAX_CANDLES:\n",
    "    test_data = test_data.tail(MAX_CANDLES).reset_index(drop=True)\n",
    "    print(f\"üìä Using last {MAX_CANDLES} candles for backtest\")\n",
    "else:\n",
    "    print(f\"üìä Using all {len(test_data)} candles\")\n",
    "\n",
    "print(f\"üìç Backtest period: {test_data['datetime'].min()} to {test_data['datetime'].max()}\")\n",
    "\n",
    "# Set datetime as index (required for VectorBT)\n",
    "test_data_indexed = test_data.set_index('datetime')\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9c92c",
   "metadata": {},
   "source": [
    "## üéØ Initialize VectorBT Backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05903dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Initializing VectorBT Backtester...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create VectorBT backtester instance with FeatureManager\n",
    "backtester = VectorBTBacktester(\n",
    "    trainer=trainer,\n",
    "    initial_cash=INITIAL_CASH,\n",
    "    commission=COMMISSION,\n",
    "    slippage=SLIPPAGE,\n",
    "    middleware_config=custom_middleware_config  # Use custom middleware config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ VectorBT Backtester initialized!\")\n",
    "print(f\"   Initial Cash:  ${backtester.initial_cash:,.2f}\")\n",
    "print(f\"   Commission:    {backtester.commission:.2%}\")\n",
    "print(f\"   Slippage:      {backtester.slippage:.2%}\")\n",
    "print(f\"   FeatureManager: Enabled ‚úÖ\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3703854",
   "metadata": {},
   "source": [
    "## üîÆ Generate Trading Signals from ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9187367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare level files (M, W, D, 1h for multi-timeframe analysis)\n",
    "level_files = {tf: path for tf, path in test_files.items() if tf in ['M', 'W', 'D', '1h']}\n",
    "\n",
    "print(\"üîÆ Generating ML trading signals with FeatureManager...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate signals using VectorBT backtester with new FeatureManager\n",
    "# Features will be cached automatically:\n",
    "# - TA features (Group 2): Calculated once for entire dataset\n",
    "# - Level features (Group 1): Updated daily\n",
    "signals_df = backtester.generate_signals(\n",
    "    data=test_data_indexed,\n",
    "    level_files=level_files,\n",
    "    buy_threshold=BUY_THRESHOLD,\n",
    "    sell_threshold=SELL_THRESHOLD,\n",
    "    timeframe='15m'  # Specify timeframe for middleware selection\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Signal Statistics:\")\n",
    "print(f\"   Total Candles:  {len(signals_df)}\")\n",
    "print(f\"   BUY Signals:    {(signals_df['signal'] == 'BUY').sum()}\")\n",
    "print(f\"   SELL Signals:   {(signals_df['signal'] == 'SELL').sum()}\")\n",
    "print(f\"   HOLD Signals:   {(signals_df['signal'] == 'HOLD').sum()}\")\n",
    "\n",
    "# Show first few signals\n",
    "print(\"\\nüìã Sample Signals:\")\n",
    "print(signals_df[['close', 'signal', 'confidence']].head(10))\n",
    "\n",
    "print(\"\\n‚úÖ Signal generation complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0625ac",
   "metadata": {},
   "source": [
    "## üöÄ Run VectorBT Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the backtest\n",
    "portfolio = backtester.run_backtest(freq=FREQ)\n",
    "\n",
    "print(\"\\nüéâ Backtest execution complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07c60ad",
   "metadata": {},
   "source": [
    "## üìä Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display formatted performance summary\n",
    "backtester.print_performance_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4cee5",
   "metadata": {},
   "source": [
    "## üìà Interactive Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0baa8c4",
   "metadata": {},
   "source": [
    "## üîß Fix: Install anywidget for Interactive Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad367c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install anywidget in the notebook kernel\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"üì¶ Installing anywidget...\")\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"anywidget\"])\n",
    "print(\"‚úÖ anywidget installed!\")\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: Restart the kernel after installation!\")\n",
    "print(\"   Go to: Kernel ‚Üí Restart Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interactive VectorBT plots\n",
    "# Using static plots (no anywidget dependency)\n",
    "backtester.plot_results(use_widgets=False)\n",
    "\n",
    "# If you want to use widgets after restarting kernel:\n",
    "# backtester.plot_results(use_widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34de00",
   "metadata": {},
   "source": [
    "## üìã Trade-by-Trade Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31adc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed trade records\n",
    "trades_df = backtester.get_trade_analysis()\n",
    "\n",
    "print(f\"üìã Total Trades: {len(trades_df)}\")\n",
    "print(\"\\nüîç Trade Details:\")\n",
    "print(trades_df.head(20))  # Show first 20 trades\n",
    "\n",
    "# Calculate some additional statistics\n",
    "if len(trades_df) > 0:\n",
    "    winning_trades = trades_df[trades_df['PnL'] > 0]\n",
    "    losing_trades = trades_df[trades_df['PnL'] < 0]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Winning Trades: {len(winning_trades)} ({len(winning_trades)/len(trades_df)*100:.1f}%)\")\n",
    "    print(f\"‚ùå Losing Trades:  {len(losing_trades)} ({len(losing_trades)/len(trades_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(winning_trades) > 0:\n",
    "        print(f\"üíö Avg Win:  ${winning_trades['PnL'].mean():.2f}\")\n",
    "        print(f\"üíö Max Win:  ${winning_trades['PnL'].max():.2f}\")\n",
    "    \n",
    "    if len(losing_trades) > 0:\n",
    "        print(f\"üíî Avg Loss: ${losing_trades['PnL'].mean():.2f}\")\n",
    "        print(f\"üíî Max Loss: ${losing_trades['PnL'].min():.2f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No trades executed during backtest period\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825f498",
   "metadata": {},
   "source": [
    "## üíæ Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3200bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all backtest results to files\n",
    "backtester.export_results(output_dir=\"backtest_results\")\n",
    "\n",
    "print(\"\\n‚úÖ All results exported successfully!\")\n",
    "print(\"   Check the 'backtest_results' folder for:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a9aca",
   "metadata": {},
   "source": [
    "## üßπ Clear Feature Cache (Optional)\n",
    "\n",
    "If you need to force recalculation of features (e.g., after data changes), you can clear the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2506d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear feature cache if needed\n",
    "if backtester.feature_manager is not None:\n",
    "    backtester.feature_manager.clear_cache()\n",
    "    print(\"‚úÖ Feature cache cleared!\")\n",
    "    print(\"   Next backtest will recalculate all features.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Feature manager not enabled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
