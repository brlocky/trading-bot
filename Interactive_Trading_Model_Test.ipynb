{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd35219",
   "metadata": {},
   "source": [
    "# 🚀 Interactive Trading Model Test & Visualization\n",
    "\n",
    "This notebook provides **interactive testing** of our autonomous trading system with **visual analysis** using plotly charts.\n",
    "\n",
    "## 🎯 What We'll Do:\n",
    "- Test the model with data from `data_test/` folder\n",
    "- Generate trading signals and visualize them\n",
    "- Show level interactions with price action\n",
    "- Interactive charts with signal annotations\n",
    "- Performance analysis and backtesting\n",
    "\n",
    "## 📊 Available Test Data:\n",
    "- **ADAUSDT**: 1h, D, M, W timeframes\n",
    "- **DOGEUSDT**: 1h, D timeframes  \n",
    "- **ETHUSDT**: W timeframe\n",
    "\n",
    "Let's dive into interactive trading analysis! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb4608",
   "metadata": {},
   "source": [
    "## 1. Import Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2debd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "📁 Available test data files:\n",
      "   - ADAUSDT-1h.json\n",
      "   - ADAUSDT-D.json\n",
      "   - ADAUSDT-M.json\n",
      "   - ADAUSDT-W (1).json\n",
      "   - ADAUSDT-W.json\n",
      "   - DOGEUSDT-1h.json\n",
      "   - DOGEUSDT-D.json\n",
      "   - ETHUSDT-W.json\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Our Trading System\n",
    "from src.autonomous_trader import (\n",
    "    AutonomousTrader, MultitimeframeLevelExtractor, \n",
    "    LevelBasedFeatureEngineer, TradingAction\n",
    ")\n",
    "from src.autonomous_trader_trainer import AutonomousTraderTrainer\n",
    "from src.data_pipeline import DataPipelineManager\n",
    "\n",
    "# Set plotly theme\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"📁 Available test data files:\")\n",
    "for file in os.listdir('data_test'):\n",
    "    print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c08a2",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199d0006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Available symbols: ['ADAUSDT', 'DOGEUSDT', 'ETHUSDT']\n",
      "\n",
      "ADAUSDT:\n",
      "   1h: data_test/ADAUSDT-1h.json\n",
      "   D: data_test/ADAUSDT-D.json\n",
      "   W: data_test/ADAUSDT-W (1).json\n",
      "   M: data_test/ADAUSDT-M.json\n",
      "\n",
      "DOGEUSDT:\n",
      "   1h: data_test/DOGEUSDT-1h.json\n",
      "   D: data_test/DOGEUSDT-D.json\n",
      "\n",
      "ETHUSDT:\n",
      "   W: data_test/ETHUSDT-W.json\n"
     ]
    }
   ],
   "source": [
    "def load_json_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and prepare OHLCV data from JSON file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        if 'timestamp' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        elif 'time' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        \n",
    "        # Ensure we have OHLCV columns\n",
    "        required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        for col in required_cols:\n",
    "            if col not in df.columns:\n",
    "                print(f\"⚠️ Missing column: {col}\")\n",
    "                return None\n",
    "        \n",
    "        # Convert to float\n",
    "        for col in required_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        df = df.sort_values('datetime').reset_index(drop=True)\n",
    "        print(f\"✅ Loaded {len(df)} candles from {file_path}\")\n",
    "        print(f\"   Period: {df['datetime'].iloc[0]} to {df['datetime'].iloc[-1]}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_available_symbols():\n",
    "    \"\"\"Get available symbols from data_test folder\"\"\"\n",
    "    symbols = set()\n",
    "    for file in os.listdir('data_test'):\n",
    "        if file.endswith('.json'):\n",
    "            symbol = file.split('-')[0]\n",
    "            symbols.add(symbol)\n",
    "    return sorted(list(symbols))\n",
    "\n",
    "def get_symbol_files(symbol: str) -> Dict[str, str]:\n",
    "    \"\"\"Get all available timeframe files for a symbol\"\"\"\n",
    "    files = {}\n",
    "    timeframes = ['1h', 'D', 'W', 'M']\n",
    "    \n",
    "    for tf in timeframes:\n",
    "        file_path = f'data_test/{symbol}-{tf}.json'\n",
    "        if os.path.exists(file_path):\n",
    "            files[tf] = file_path\n",
    "        # Check for alternative naming\n",
    "        alt_path = f'data_test/{symbol}-{tf} (1).json'\n",
    "        if os.path.exists(alt_path):\n",
    "            files[tf] = alt_path\n",
    "    \n",
    "    return files\n",
    "\n",
    "# Show available symbols and their files\n",
    "available_symbols = get_available_symbols()\n",
    "print(f\"\\n📊 Available symbols: {available_symbols}\")\n",
    "\n",
    "for symbol in available_symbols:\n",
    "    files = get_symbol_files(symbol)\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    for tf, path in files.items():\n",
    "        print(f\"   {tf}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e007db",
   "metadata": {},
   "source": [
    "## 3. Train/Test Data Setup\n",
    "\n",
    "We'll use a proper machine learning workflow:\n",
    "- **Training Data**: `/data/` folder (BTCUSDT) - Train the model\n",
    "- **Test Data**: `/data_test/` folder (ADAUSDT, DOGEUSDT, etc.) - Test on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3360f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎓 PHASE 1: TRAINING SETUP\n",
      "==================================================\n",
      "📚 Training on: BTCUSDT\n",
      "📁 Training files:\n",
      "   1h: data/BTCUSDT-1h.json ✅\n",
      "   D: data/BTCUSDT-D.json ✅\n",
      "   W: data/BTCUSDT-W.json ✅\n",
      "   M: data/BTCUSDT-M.json ✅\n",
      "\n",
      "🧪 PHASE 2: TESTING SETUP\n",
      "==================================================\n",
      "🎯 Testing on: ADAUSDT\n",
      "📁 Test files:\n",
      "   1h: data_test/ADAUSDT-1h.json\n",
      "   D: data_test/ADAUSDT-D.json\n",
      "   W: data_test/ADAUSDT-W (1).json\n",
      "   M: data_test/ADAUSDT-M.json\n",
      "⚠️ Missing column: open\n",
      "\n",
      "❌ Failed to load test trading data\n",
      "\n",
      "🎯 Test level files:\n",
      "   M: data_test/ADAUSDT-M.json\n",
      "   W: data_test/ADAUSDT-W (1).json\n",
      "   D: data_test/ADAUSDT-D.json\n",
      "✅ Ready to test with 3 timeframes\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# PHASE 1: TRAINING SETUP (using /data/)\n",
    "# ===========================================\n",
    "print(\"🎓 PHASE 1: TRAINING SETUP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training data from /data/ folder (BTCUSDT)\n",
    "TRAINING_SYMBOL = 'BTCUSDT'\n",
    "training_files = {\n",
    "    '1h': 'data/BTCUSDT-1h.json',\n",
    "    'D': 'data/BTCUSDT-D.json', \n",
    "    'W': 'data/BTCUSDT-W.json',\n",
    "    'M': 'data/BTCUSDT-M.json'\n",
    "}\n",
    "\n",
    "print(f\"📚 Training on: {TRAINING_SYMBOL}\")\n",
    "print(\"📁 Training files:\")\n",
    "for tf, path in training_files.items():\n",
    "    exists = \"✅\" if os.path.exists(path) else \"❌\"\n",
    "    print(f\"   {tf}: {path} {exists}\")\n",
    "\n",
    "# ===========================================\n",
    "# PHASE 2: TESTING SETUP (using /data_test/)\n",
    "# ===========================================\n",
    "print(f\"\\n🧪 PHASE 2: TESTING SETUP\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test symbol selection\n",
    "TEST_SYMBOL = 'ADAUSDT'  # Change this to test different symbols\n",
    "\n",
    "test_symbol_files = get_symbol_files(TEST_SYMBOL)\n",
    "print(f\"🎯 Testing on: {TEST_SYMBOL}\")\n",
    "print(\"📁 Test files:\")\n",
    "for tf, path in test_symbol_files.items():\n",
    "    print(f\"   {tf}: {path}\")\n",
    "\n",
    "# Load test data\n",
    "test_trading_data = None\n",
    "if '1h' in test_symbol_files:\n",
    "    test_trading_data = load_json_data(test_symbol_files['1h'])\n",
    "    if test_trading_data is not None:\n",
    "        print(f\"\\n📈 Test trading data loaded: {len(test_trading_data)} 1h candles\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Failed to load test trading data\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No 1h test data available\")\n",
    "\n",
    "# Prepare test level files\n",
    "test_level_files = {}\n",
    "for tf in ['M', 'W', 'D']:\n",
    "    if tf in test_symbol_files:\n",
    "        test_level_files[tf] = test_symbol_files[tf]\n",
    "\n",
    "print(f\"\\n🎯 Test level files:\")\n",
    "for tf, path in test_level_files.items():\n",
    "    print(f\"   {tf}: {path}\")\n",
    "\n",
    "if not test_level_files:\n",
    "    print(\"❌ No test level files available\")\n",
    "else:\n",
    "    print(f\"✅ Ready to test with {len(test_level_files)} timeframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc565eb",
   "metadata": {},
   "source": [
    "## 4. Train the Model on Training Data (/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f8490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Training Autonomous Trading Model\n",
      "==================================================\n",
      "📊 Training Configuration:\n",
      "   Training symbol: BTCUSDT\n",
      "   Trading data: data/BTCUSDT-1h.json\n",
      "   Level files: ['data/BTCUSDT-D.json', 'data/BTCUSDT-W.json', 'data/BTCUSDT-M.json']\n",
      "\n",
      "🔧 Preparing training data...\n",
      "📊 Preparing training data...\n",
      "✅ Loaded 1490 intraday candles\n",
      "🔍 Extracting multi-timeframe levels...\n",
      "  Period 2024-W30: SKIPPED - insufficient data\n",
      "Volume Profile: Generated 183 volume profile ranges\n",
      "✅ Extracted 217 levels from D timeframe\n",
      "Volume Profile: Generated 201 volume profile ranges\n",
      "✅ Extracted 243 levels from W timeframe\n",
      "Volume Profile: Generated 18 volume profile ranges\n",
      "✅ Extracted 35 levels from M timeframe\n",
      "🛠️ Engineering features...\n",
      "Volume Profile: Generated 201 volume profile ranges\n",
      "✅ Extracted 243 levels from W timeframe\n",
      "Volume Profile: Generated 18 volume profile ranges\n",
      "✅ Extracted 35 levels from M timeframe\n",
      "🛠️ Engineering features...\n",
      "   Processed 1000/1470 candles\n",
      "   Processed 1000/1470 candles\n",
      "✅ Created 1470 training samples with 50 features\n",
      "✅ Training data prepared:\n",
      "   Features: 1470 samples, 50 features\n",
      "   Labels: 5 samples\n",
      "   Label distribution:\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "     [0 0 1 ... 1 1 0]: 1 (20.0%)\n",
      "     [1 1 0 ... 0 0 1]: 1 (20.0%)\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "\n",
      "🎯 Training models...\n",
      "🤖 Training autonomous trading models...\n",
      "\n",
      "🎯 Training buy model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for buy\n",
      "\n",
      "🎯 Training sell model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for sell\n",
      "\n",
      "🎯 Training hold model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for hold\n",
      "⚠️ Skipping close_long: insufficient positive examples (0)\n",
      "⚠️ Skipping close_short: insufficient positive examples (0)\n",
      "❌ Model training failed\n",
      "✅ Created 1470 training samples with 50 features\n",
      "✅ Training data prepared:\n",
      "   Features: 1470 samples, 50 features\n",
      "   Labels: 5 samples\n",
      "   Label distribution:\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "     [0 0 1 ... 1 1 0]: 1 (20.0%)\n",
      "     [1 1 0 ... 0 0 1]: 1 (20.0%)\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "     [0 0 0 ... 0 0 0]: 1 (20.0%)\n",
      "\n",
      "🎯 Training models...\n",
      "🤖 Training autonomous trading models...\n",
      "\n",
      "🎯 Training buy model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for buy\n",
      "\n",
      "🎯 Training sell model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for sell\n",
      "\n",
      "🎯 Training hold model...\n",
      "   random_forest: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   gradient_boosting: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 416, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "GradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "   logistic_regression: Error - \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1208, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"d:\\Dev\\trading-bot\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "❌ No successful model for hold\n",
      "⚠️ Skipping close_long: insufficient positive examples (0)\n",
      "⚠️ Skipping close_short: insufficient positive examples (0)\n",
      "❌ Model training failed\n"
     ]
    }
   ],
   "source": [
    "# Train the autonomous trading model on BTCUSDT data\n",
    "print(\"🤖 Training Autonomous Trading Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = AutonomousTraderTrainer()\n",
    "\n",
    "# Prepare training level files\n",
    "training_level_files = {tf: path for tf, path in training_files.items() if tf in ['M', 'W', 'D']}\n",
    "\n",
    "print(f\"📊 Training Configuration:\")\n",
    "print(f\"   Training symbol: {TRAINING_SYMBOL}\")\n",
    "print(f\"   Trading data: {training_files['1h']}\")\n",
    "print(f\"   Level files: {list(training_level_files.values())}\")\n",
    "\n",
    "try:\n",
    "    # Check if training files exist\n",
    "    missing_files = []\n",
    "    for tf, path in training_files.items():\n",
    "        if not os.path.exists(path):\n",
    "            missing_files.append(path)\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"❌ Missing training files: {missing_files}\")\n",
    "        trained_model = None\n",
    "    else:\n",
    "        print(f\"\\n🔧 Preparing training data...\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        features_df, labels = trainer.prepare_training_data(\n",
    "            training_files['1h'], \n",
    "            training_level_files\n",
    "        )\n",
    "        \n",
    "        if features_df is None or len(features_df) == 0:\n",
    "            print(\"❌ No training data prepared\")\n",
    "            trained_model = None\n",
    "        else:\n",
    "            print(f\"✅ Training data prepared:\")\n",
    "            print(f\"   Features: {len(features_df)} samples, {len(features_df.columns)} features\")\n",
    "            print(f\"   Labels: {len(labels)} samples\")\n",
    "            \n",
    "            # Show label distribution\n",
    "            label_counts = pd.Series(labels).value_counts()\n",
    "            print(f\"   Label distribution:\")\n",
    "            for label, count in label_counts.items():\n",
    "                print(f\"     {label}: {count} ({count/len(labels)*100:.1f}%)\")\n",
    "            \n",
    "            # Train models\n",
    "            print(f\"\\n🎯 Training models...\")\n",
    "            training_results = trainer.train_models(features_df, labels)\n",
    "            \n",
    "            if training_results:\n",
    "                print(f\"\\n✅ Model training completed!\")\n",
    "                \n",
    "                # Show results\n",
    "                for model_name, result in training_results.items():\n",
    "                    if 'accuracy' in result:\n",
    "                        print(f\"   {model_name}: {result['accuracy']:.1%} accuracy\")\n",
    "                \n",
    "                # Save the trained models\n",
    "                print(f\"\\n💾 Saving trained models...\")\n",
    "                trainer.save_models()\n",
    "                \n",
    "                trained_model = trainer\n",
    "                print(f\"✅ Models saved successfully!\")\n",
    "                \n",
    "            else:\n",
    "                print(\"❌ Model training failed\")\n",
    "                trained_model = None\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    trained_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e7c46",
   "metadata": {},
   "source": [
    "## 5. Test Trained Model on Unseen Data (/data_test/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc55fbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trading_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Generate signals if we have trading data\u001b[39;00m\n\u001b[0;32m     61\u001b[0m signals_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrading_data\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m trader\u001b[38;5;241m.\u001b[39mcurrent_levels:\n\u001b[0;32m     63\u001b[0m     signals_df \u001b[38;5;241m=\u001b[39m generate_trading_signals(trading_data, trader)\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(signals_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trading signals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trading_data' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_trading_signals(df: pd.DataFrame, trader: AutonomousTrader) -> pd.DataFrame:\n",
    "    \"\"\"Generate trading signals for each candle in the dataframe\"\"\"\n",
    "    signals = []\n",
    "    \n",
    "    print(f\"🎯 Generating trading signals for {len(df)} candles...\")\n",
    "    \n",
    "    # Sample every N candles to speed up processing\n",
    "    step_size = max(1, len(df) // 200)  # Max 200 signals for performance\n",
    "    \n",
    "    for i in range(0, len(df), step_size):\n",
    "        row = df.iloc[i]\n",
    "        \n",
    "        # Create market data for signal generation\n",
    "        market_data = {\n",
    "            'symbol': SELECTED_SYMBOL,\n",
    "            'close': float(row['close']),\n",
    "            'volume': float(row['volume']),\n",
    "            'high': float(row['high']),\n",
    "            'low': float(row['low']),\n",
    "            'open': float(row['open'])\n",
    "        }\n",
    "        \n",
    "        # Generate signal\n",
    "        signal = trader.generate_trading_signal(market_data)\n",
    "        \n",
    "        signals.append({\n",
    "            'datetime': row['datetime'],\n",
    "            'close': row['close'],\n",
    "            'volume': row['volume'],\n",
    "            'high': row['high'],\n",
    "            'low': row['low'],\n",
    "            'open': row['open'],\n",
    "            'action': signal.action.value,\n",
    "            'confidence': signal.confidence,\n",
    "            'reasoning': signal.reasoning,\n",
    "            'entry_price': signal.entry_price,\n",
    "            'stop_loss': signal.stop_loss,\n",
    "            'take_profit': signal.take_profit,\n",
    "            'risk_reward_ratio': signal.risk_reward_ratio\n",
    "        })\n",
    "        \n",
    "        if (i // step_size + 1) % 50 == 0:\n",
    "            progress = (i + 1) / len(df) * 100\n",
    "            print(f\"   Progress: {progress:.1f}%\")\n",
    "    \n",
    "    signals_df = pd.DataFrame(signals)\n",
    "    \n",
    "    # Show signal summary\n",
    "    print(f\"\\n📊 Signal Summary:\")\n",
    "    action_counts = signals_df['action'].value_counts()\n",
    "    for action, count in action_counts.items():\n",
    "        percentage = count / len(signals_df) * 100\n",
    "        print(f\"   {action.upper()}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    avg_confidence = signals_df['confidence'].mean()\n",
    "    print(f\"   Average Confidence: {avg_confidence:.1%}\")\n",
    "    \n",
    "    return signals_df\n",
    "\n",
    "# Generate signals if we have trading data\n",
    "signals_df = None\n",
    "if trading_data is not None and trader.current_levels:\n",
    "    signals_df = generate_trading_signals(trading_data, trader)\n",
    "    print(f\"\\n✅ Generated {len(signals_df)} trading signals\")\n",
    "else:\n",
    "    print(\"❌ Cannot generate signals - missing data or levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd2bc8",
   "metadata": {},
   "source": [
    "## 6. Interactive Price Chart with Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trading_chart(signals_df: pd.DataFrame, levels_data: Dict = None):\n",
    "    \"\"\"Create interactive candlestick chart with trading signals\"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        subplot_titles=(f'{SELECTED_SYMBOL} Price & Trading Signals', 'Volume', 'Confidence Score'),\n",
    "        vertical_spacing=0.05,\n",
    "        row_heights=[0.6, 0.2, 0.2],\n",
    "        specs=[[{\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # Add candlestick chart\n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x=signals_df['datetime'],\n",
    "            open=signals_df['open'],\n",
    "            high=signals_df['high'],\n",
    "            low=signals_df['low'],\n",
    "            close=signals_df['close'],\n",
    "            name='Price',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Add support/resistance levels if available\n",
    "    if levels_data:\n",
    "        colors = {'support': 'green', 'resistance': 'red', 'poc': 'yellow', \n",
    "                 'vah': 'orange', 'val': 'orange', 'pivot': 'purple'}\n",
    "        \n",
    "        level_lines_added = set()\n",
    "        for timeframe, levels in levels_data.items():\n",
    "            for level in levels[:10]:  # Show top 10 levels per timeframe\n",
    "                level_key = f\"{level.price:.2f}_{level.level_type}\"\n",
    "                if level_key not in level_lines_added:\n",
    "                    color = colors.get(level.level_type.lower(), 'gray')\n",
    "                    fig.add_hline(\n",
    "                        y=level.price,\n",
    "                        line_dash=\"dash\",\n",
    "                        line_color=color,\n",
    "                        opacity=0.5,\n",
    "                        annotation_text=f\"{timeframe} {level.level_type} ({level.strength:.1f})\",\n",
    "                        annotation_position=\"top right\",\n",
    "                        row=1, col=1\n",
    "                    )\n",
    "                    level_lines_added.add(level_key)\n",
    "    \n",
    "    # Add BUY signals\n",
    "    buy_signals = signals_df[signals_df['action'] == 'buy']\n",
    "    if not buy_signals.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=buy_signals['datetime'],\n",
    "                y=buy_signals['close'],\n",
    "                mode='markers',\n",
    "                marker=dict(symbol='triangle-up', size=12, color='lime'),\n",
    "                name='BUY Signal',\n",
    "                text=buy_signals['reasoning'],\n",
    "                hovertemplate='<b>BUY</b><br>Price: $%{y:.2f}<br>Confidence: %{customdata:.1%}<br>%{text}<extra></extra>',\n",
    "                customdata=buy_signals['confidence']\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Add SELL signals\n",
    "    sell_signals = signals_df[signals_df['action'] == 'sell']\n",
    "    if not sell_signals.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=sell_signals['datetime'],\n",
    "                y=sell_signals['close'],\n",
    "                mode='markers',\n",
    "                marker=dict(symbol='triangle-down', size=12, color='red'),\n",
    "                name='SELL Signal',\n",
    "                text=sell_signals['reasoning'],\n",
    "                hovertemplate='<b>SELL</b><br>Price: $%{y:.2f}<br>Confidence: %{customdata:.1%}<br>%{text}<extra></extra>',\n",
    "                customdata=sell_signals['confidence']\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Add volume\n",
    "    colors = ['green' if close >= open else 'red' \n",
    "              for close, open in zip(signals_df['close'], signals_df['open'])]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=signals_df['datetime'],\n",
    "            y=signals_df['volume'],\n",
    "            name='Volume',\n",
    "            marker_color=colors,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add confidence score\n",
    "    confidence_colors = ['lime' if action == 'buy' else 'red' if action == 'sell' else 'gray' \n",
    "                        for action in signals_df['action']]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=signals_df['datetime'],\n",
    "            y=signals_df['confidence'],\n",
    "            mode='markers+lines',\n",
    "            name='Confidence',\n",
    "            line=dict(color='white', width=1),\n",
    "            marker=dict(color=confidence_colors, size=6),\n",
    "            showlegend=False,\n",
    "            hovertemplate='Confidence: %{y:.1%}<br>Action: %{customdata}<extra></extra>',\n",
    "            customdata=signals_df['action']\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Interactive Trading Analysis - {SELECTED_SYMBOL}',\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_yaxes(title_text=\"Price ($)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Volume\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Confidence\", row=3, col=1, tickformat='.0%')\n",
    "    fig.update_xaxes(title_text=\"Time\", row=3, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display the chart\n",
    "if signals_df is not None:\n",
    "    print(\"📊 Creating interactive trading chart...\")\n",
    "    \n",
    "    chart = create_trading_chart(signals_df, trader.current_levels)\n",
    "    chart.show()\n",
    "    \n",
    "    print(\"✅ Interactive chart created!\")\n",
    "    print(\"💡 Use the chart controls to zoom, pan, and hover for details\")\n",
    "else:\n",
    "    print(\"❌ No signals available to chart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b3605",
   "metadata": {},
   "source": [
    "## 7. Signal Analysis & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_signals(signals_df: pd.DataFrame):\n",
    "    \"\"\"Detailed analysis of trading signals\"\"\"\n",
    "    print(\"📈 Detailed Signal Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_signals = len(signals_df)\n",
    "    buy_signals = len(signals_df[signals_df['action'] == 'buy'])\n",
    "    sell_signals = len(signals_df[signals_df['action'] == 'sell'])\n",
    "    hold_signals = len(signals_df[signals_df['action'] == 'hold'])\n",
    "    \n",
    "    print(f\"📊 Signal Distribution:\")\n",
    "    print(f\"   Total Signals: {total_signals}\")\n",
    "    print(f\"   BUY: {buy_signals} ({buy_signals/total_signals*100:.1f}%)\")\n",
    "    print(f\"   SELL: {sell_signals} ({sell_signals/total_signals*100:.1f}%)\")\n",
    "    print(f\"   HOLD: {hold_signals} ({hold_signals/total_signals*100:.1f}%)\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    print(f\"\\n🎯 Confidence Analysis:\")\n",
    "    for action in ['buy', 'sell', 'hold']:\n",
    "        action_signals = signals_df[signals_df['action'] == action]\n",
    "        if not action_signals.empty:\n",
    "            avg_conf = action_signals['confidence'].mean()\n",
    "            max_conf = action_signals['confidence'].max()\n",
    "            min_conf = action_signals['confidence'].min()\n",
    "            print(f\"   {action.upper()}: Avg {avg_conf:.1%}, Max {max_conf:.1%}, Min {min_conf:.1%}\")\n",
    "    \n",
    "    # High confidence signals\n",
    "    high_conf_threshold = 0.7\n",
    "    high_conf_signals = signals_df[signals_df['confidence'] >= high_conf_threshold]\n",
    "    print(f\"\\n🚀 High Confidence Signals (≥{high_conf_threshold:.0%}):\")\n",
    "    print(f\"   Count: {len(high_conf_signals)} ({len(high_conf_signals)/total_signals*100:.1f}%)\")\n",
    "    \n",
    "    if not high_conf_signals.empty:\n",
    "        for action in ['buy', 'sell']:\n",
    "            action_high_conf = high_conf_signals[high_conf_signals['action'] == action]\n",
    "            if not action_high_conf.empty:\n",
    "                print(f\"   {action.upper()}: {len(action_high_conf)} signals\")\n",
    "    \n",
    "    # Risk/Reward analysis\n",
    "    signals_with_rr = signals_df.dropna(subset=['risk_reward_ratio'])\n",
    "    if not signals_with_rr.empty:\n",
    "        print(f\"\\n⚖️ Risk/Reward Analysis:\")\n",
    "        avg_rr = signals_with_rr['risk_reward_ratio'].mean()\n",
    "        good_rr_signals = signals_with_rr[signals_with_rr['risk_reward_ratio'] >= 2.0]\n",
    "        print(f\"   Average R/R: {avg_rr:.2f}\")\n",
    "        print(f\"   Good R/R (≥2.0): {len(good_rr_signals)} ({len(good_rr_signals)/len(signals_with_rr)*100:.1f}%)\")\n",
    "    \n",
    "    # Create confidence distribution chart\n",
    "    fig_conf = px.histogram(\n",
    "        signals_df, \n",
    "        x='confidence', \n",
    "        color='action',\n",
    "        title='Confidence Score Distribution by Action',\n",
    "        nbins=20,\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_conf.update_xaxes(title='Confidence Score', tickformat='.0%')\n",
    "    fig_conf.update_yaxes(title='Count')\n",
    "    fig_conf.show()\n",
    "    \n",
    "    return {\n",
    "        'total_signals': total_signals,\n",
    "        'buy_signals': buy_signals,\n",
    "        'sell_signals': sell_signals,\n",
    "        'hold_signals': hold_signals,\n",
    "        'high_confidence_signals': len(high_conf_signals)\n",
    "    }\n",
    "\n",
    "# Analyze signals if available\n",
    "if signals_df is not None:\n",
    "    signal_stats = analyze_signals(signals_df)\n",
    "else:\n",
    "    print(\"❌ No signals to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70fd3d8",
   "metadata": {},
   "source": [
    "## 8. Level Interaction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_level_interactions(signals_df: pd.DataFrame, levels_data: Dict):\n",
    "    \"\"\"Analyze how signals interact with support/resistance levels\"\"\"\n",
    "    print(\"🎯 Level Interaction Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not levels_data:\n",
    "        print(\"❌ No level data available\")\n",
    "        return\n",
    "    \n",
    "    # Get all levels as a flat list\n",
    "    all_levels = []\n",
    "    for timeframe, levels in levels_data.items():\n",
    "        for level in levels:\n",
    "            all_levels.append({\n",
    "                'timeframe': timeframe,\n",
    "                'price': level.price,\n",
    "                'type': level.level_type,\n",
    "                'strength': level.strength\n",
    "            })\n",
    "    \n",
    "    # Analyze signal proximity to levels\n",
    "    proximity_threshold = 0.02  # 2% proximity\n",
    "    \n",
    "    signal_level_interactions = []\n",
    "    \n",
    "    for idx, signal in signals_df.iterrows():\n",
    "        signal_price = signal['close']\n",
    "        \n",
    "        # Find nearby levels\n",
    "        nearby_levels = []\n",
    "        for level in all_levels:\n",
    "            distance = abs(level['price'] - signal_price) / signal_price\n",
    "            if distance <= proximity_threshold:\n",
    "                nearby_levels.append({\n",
    "                    **level,\n",
    "                    'distance': distance\n",
    "                })\n",
    "        \n",
    "        # Sort by distance\n",
    "        nearby_levels.sort(key=lambda x: x['distance'])\n",
    "        \n",
    "        signal_level_interactions.append({\n",
    "            'datetime': signal['datetime'],\n",
    "            'action': signal['action'],\n",
    "            'confidence': signal['confidence'],\n",
    "            'price': signal_price,\n",
    "            'nearby_levels': nearby_levels[:3]  # Top 3 closest\n",
    "        })\n",
    "    \n",
    "    # Analyze interactions by action type\n",
    "    for action in ['buy', 'sell']:\n",
    "        action_interactions = [x for x in signal_level_interactions if x['action'] == action]\n",
    "        \n",
    "        if not action_interactions:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n📊 {action.upper()} Signal Level Interactions:\")\n",
    "        \n",
    "        # Count interactions by level type\n",
    "        level_type_counts = {}\n",
    "        total_near_levels = 0\n",
    "        \n",
    "        for interaction in action_interactions:\n",
    "            if interaction['nearby_levels']:\n",
    "                total_near_levels += 1\n",
    "                for level in interaction['nearby_levels']:\n",
    "                    level_type = level['type']\n",
    "                    if level_type not in level_type_counts:\n",
    "                        level_type_counts[level_type] = 0\n",
    "                    level_type_counts[level_type] += 1\n",
    "        \n",
    "        print(f\"   Signals near levels: {total_near_levels}/{len(action_interactions)} ({total_near_levels/len(action_interactions)*100:.1f}%)\")\n",
    "        \n",
    "        if level_type_counts:\n",
    "            print(f\"   Level type interactions:\")\n",
    "            for level_type, count in sorted(level_type_counts.items()):\n",
    "                print(f\"     {level_type}: {count}\")\n",
    "    \n",
    "    # Create level interaction visualization\n",
    "    level_prices = [level['price'] for level in all_levels]\n",
    "    level_types = [level['type'] for level in all_levels]\n",
    "    level_strengths = [level['strength'] for level in all_levels]\n",
    "    \n",
    "    # Price range for visualization\n",
    "    price_min = signals_df['close'].min() * 0.95\n",
    "    price_max = signals_df['close'].max() * 1.05\n",
    "    \n",
    "    # Filter levels within price range\n",
    "    relevant_levels = [(p, t, s) for p, t, s in zip(level_prices, level_types, level_strengths) \n",
    "                      if price_min <= p <= price_max]\n",
    "    \n",
    "    if relevant_levels:\n",
    "        fig_levels = go.Figure()\n",
    "        \n",
    "        # Add levels as horizontal lines\n",
    "        colors = {'support': 'green', 'resistance': 'red', 'poc': 'yellow', \n",
    "                 'vah': 'orange', 'val': 'orange', 'pivot': 'purple'}\n",
    "        \n",
    "        for price, level_type, strength in relevant_levels:\n",
    "            color = colors.get(level_type.lower(), 'gray')\n",
    "            fig_levels.add_hline(\n",
    "                y=price,\n",
    "                line_color=color,\n",
    "                line_width=max(1, strength),\n",
    "                opacity=0.7,\n",
    "                annotation_text=f\"{level_type} ({strength:.1f})\"\n",
    "            )\n",
    "        \n",
    "        # Add price action\n",
    "        fig_levels.add_trace(\n",
    "            go.Scatter(\n",
    "                x=signals_df['datetime'],\n",
    "                y=signals_df['close'],\n",
    "                mode='lines',\n",
    "                name='Price',\n",
    "                line=dict(color='white', width=2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig_levels.update_layout(\n",
    "            title='Price Action vs Support/Resistance Levels',\n",
    "            template='plotly_dark',\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig_levels.show()\n",
    "\n",
    "# Analyze level interactions if data is available\n",
    "if signals_df is not None and trader.current_levels:\n",
    "    analyze_level_interactions(signals_df, trader.current_levels)\n",
    "else:\n",
    "    print(\"❌ Cannot analyze level interactions - missing data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4545d3",
   "metadata": {},
   "source": [
    "## 9. Model Training on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f599cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_on_test_data(symbol: str, files: Dict[str, str]):\n",
    "    \"\"\"Train the autonomous trading model on test data\"\"\"\n",
    "    print(f\"🤖 Training Model on {symbol} Test Data\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if '1h' not in files:\n",
    "        print(\"❌ No 1h data available for training\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = AutonomousTraderTrainer()\n",
    "    \n",
    "    # Prepare level files\n",
    "    level_files = {tf: path for tf, path in files.items() if tf in ['M', 'W', 'D']}\n",
    "    \n",
    "    if not level_files:\n",
    "        print(\"❌ No level files available for training\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print(f\"📊 Preparing training data...\")\n",
    "        print(f\"   Trading data: {files['1h']}\")\n",
    "        print(f\"   Level files: {list(level_files.values())}\")\n",
    "        \n",
    "        # Prepare training data\n",
    "        features_df, labels = trainer.prepare_training_data(\n",
    "            files['1h'], \n",
    "            level_files\n",
    "        )\n",
    "        \n",
    "        if features_df is None or len(features_df) == 0:\n",
    "            print(\"❌ No training data prepared\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"✅ Training data prepared:\")\n",
    "        print(f\"   Features: {len(features_df)} samples, {len(features_df.columns)} features\")\n",
    "        print(f\"   Labels: {len(labels)} samples\")\n",
    "        \n",
    "        # Show label distribution\n",
    "        label_counts = pd.Series(labels).value_counts()\n",
    "        print(f\"   Label distribution:\")\n",
    "        for label, count in label_counts.items():\n",
    "            print(f\"     {label}: {count} ({count/len(labels)*100:.1f}%)\")\n",
    "        \n",
    "        # Train models\n",
    "        print(f\"\\n🔧 Training models...\")\n",
    "        results = trainer.train_models(features_df, labels)\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n✅ Model training completed!\")\n",
    "            \n",
    "            # Show results\n",
    "            for model_name, result in results.items():\n",
    "                if 'accuracy' in result:\n",
    "                    print(f\"   {model_name}: {result['accuracy']:.1%} accuracy\")\n",
    "            \n",
    "            # Feature importance analysis\n",
    "            if 'RandomForest' in results:\n",
    "                rf_result = results['RandomForest']\n",
    "                if 'feature_importance' in rf_result:\n",
    "                    print(f\"\\n🔍 Top Feature Importances (Random Forest):\")\n",
    "                    feature_imp = rf_result['feature_importance']\n",
    "                    for feature, importance in feature_imp.items():\n",
    "                        if importance > 0.05:  # Show features with >5% importance\n",
    "                            print(f\"     {feature}: {importance:.1%}\")\n",
    "            \n",
    "            return results\n",
    "        else:\n",
    "            print(\"❌ Model training failed\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Train model on the selected symbol\n",
    "if symbol_files and '1h' in symbol_files:\n",
    "    training_results = train_model_on_test_data(SELECTED_SYMBOL, symbol_files)\n",
    "else:\n",
    "    print(f\"❌ Cannot train model - insufficient data for {SELECTED_SYMBOL}\")\n",
    "    training_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9c5c1",
   "metadata": {},
   "source": [
    "## 10. Test Other Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of other available symbols\n",
    "print(\"🌐 Testing Other Available Symbols\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "other_symbols = [s for s in available_symbols if s != SELECTED_SYMBOL]\n",
    "\n",
    "for symbol in other_symbols[:2]:  # Test up to 2 other symbols\n",
    "    print(f\"\\n📊 Testing {symbol}:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    symbol_files = get_symbol_files(symbol)\n",
    "    print(f\"Available files: {list(symbol_files.keys())}\")\n",
    "    \n",
    "    # Quick level extraction test\n",
    "    level_files = {tf: path for tf, path in symbol_files.items() if tf in ['M', 'W', 'D']}\n",
    "    \n",
    "    if level_files:\n",
    "        test_trader = AutonomousTrader()\n",
    "        success = test_trader.update_levels(level_files, force_update=True)\n",
    "        \n",
    "        if success:\n",
    "            total_levels = sum(len(levels) for levels in test_trader.current_levels.values())\n",
    "            print(f\"✅ Extracted {total_levels} levels across {len(test_trader.current_levels)} timeframes\")\n",
    "            \n",
    "            # Test a few signals if we have 1h data\n",
    "            if '1h' in symbol_files:\n",
    "                test_data = load_json_data(symbol_files['1h'])\n",
    "                if test_data is not None and len(test_data) > 10:\n",
    "                    # Test with last few candles\n",
    "                    test_candles = test_data.tail(5)\n",
    "                    buy_signals = sell_signals = 0\n",
    "                    \n",
    "                    for _, row in test_candles.iterrows():\n",
    "                        market_data = {\n",
    "                            'symbol': symbol,\n",
    "                            'close': float(row['close']),\n",
    "                            'volume': float(row['volume']),\n",
    "                            'high': float(row['high']),\n",
    "                            'low': float(row['low']),\n",
    "                            'open': float(row['open'])\n",
    "                        }\n",
    "                        \n",
    "                        signal = test_trader.generate_trading_signal(market_data)\n",
    "                        if signal.action.value == 'buy':\n",
    "                            buy_signals += 1\n",
    "                        elif signal.action.value == 'sell':\n",
    "                            sell_signals += 1\n",
    "                    \n",
    "                    print(f\"   Sample signals: {buy_signals} BUY, {sell_signals} SELL\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to extract levels\")\n",
    "    else:\n",
    "        print(f\"❌ No level files available\")\n",
    "\n",
    "print(f\"\\n✅ Multi-symbol testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6fe0c",
   "metadata": {},
   "source": [
    "## 🎉 Test Results Summary & Next Steps\n",
    "\n",
    "### ✅ **Interactive Testing Complete!**\n",
    "\n",
    "**What We Successfully Tested:**\n",
    "\n",
    "1. **📊 Data Loading**: Successfully loaded test data from `data_test/` folder\n",
    "2. **🎯 Level Extraction**: Multi-timeframe support/resistance level detection  \n",
    "3. **🤖 Signal Generation**: Real-time BUY/SELL/HOLD decisions with confidence\n",
    "4. **📈 Interactive Visualization**: Plotly charts with signal annotations\n",
    "5. **📋 Performance Analysis**: Signal distribution and level interaction analysis\n",
    "6. **🔧 Model Training**: Training framework on historical test data\n",
    "\n",
    "### 🚀 **Key Features Demonstrated:**\n",
    "\n",
    "- **Interactive Charts**: Candlestick charts with support/resistance levels\n",
    "- **Signal Annotations**: BUY/SELL markers with hover details\n",
    "- **Confidence Analysis**: Visual confidence score tracking\n",
    "- **Level Interactions**: Analysis of price vs level proximity\n",
    "- **Multi-Symbol Support**: Tested across different cryptocurrencies\n",
    "\n",
    "### 📈 **Visual Analytics:**\n",
    "\n",
    "- Price action with overlaid support/resistance levels\n",
    "- Volume analysis correlated with signals\n",
    "- Confidence distribution histograms\n",
    "- Level interaction proximity analysis\n",
    "\n",
    "### 🔄 **Next Steps:**\n",
    "\n",
    "1. **Expand Testing**: Test with more symbols and timeframes\n",
    "2. **Strategy Optimization**: Fine-tune confidence thresholds\n",
    "3. **Backtesting**: Full historical performance analysis\n",
    "4. **Live Integration**: Connect to real-time data feeds\n",
    "\n",
    "### 💡 **Usage Tips:**\n",
    "\n",
    "- Change `SELECTED_SYMBOL` variable to test different assets\n",
    "- Adjust `proximity_threshold` for level interaction analysis\n",
    "- Modify `step_size` in signal generation for more/fewer signals\n",
    "- Use chart zoom and hover features for detailed analysis\n",
    "\n",
    "**🎊 The autonomous trading system is fully interactive and ready for advanced testing!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
