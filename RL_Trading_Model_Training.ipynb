{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18720820",
   "metadata": {},
   "source": [
    "# RL Trading Model Training & Evaluation\n",
    "\n",
    "This notebook demonstrates how to train a reinforcement learning (RL) trading model using your full feature pipeline and visualize the results. It loads historical price data, extracts features, trains a PPO agent, and evaluates performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798ff339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added to Python path: d:\\Dev\\trading-bot\\src\n",
      "📂 Working directory: d:\\Dev\\trading-bot\n",
      "🔍 Python will search for modules in: d:\\Dev\\trading-bot\\src\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# 🔧 SETUP - Add src to Python Path\n",
    "# ================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path so 'core' module can be found\n",
    "project_root = os.getcwd()\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "    print(f\"✅ Added to Python path: {src_path}\")\n",
    "else:\n",
    "    print(f\"✅ Already in path: {src_path}\")\n",
    "\n",
    "# Verify\n",
    "print(f\"📂 Working directory: {project_root}\")\n",
    "print(f\"🔍 Python will search for modules in: {src_path}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62612fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "\n",
    "# Project modules\n",
    "\n",
    "\n",
    "\n",
    "# Section 2: Load and Prepare Data\n",
    "from src.core.trading_types import ChartInterval\n",
    "from src.training.data_loader import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# Data Loader\n",
    "loader = DataLoader()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223bb4d",
   "metadata": {},
   "source": [
    "## Section 3: Train the RL Model\n",
    "\n",
    "Train a PPO agent using the extracted features and visualize training progress.\n",
    "\n",
    "**Key Improvements for Stability:**\n",
    "- ✅ **Data Normalization**: All features properly normalized (fixes massive loss values)\n",
    "- ✅ **Optimized Hyperparameters**: Tuned for 672-window observation space\n",
    "- ✅ **GPU Acceleration**: Uses RTX 3080 for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9beb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting RL Model Training...\n",
      "==================================================\n",
      "📥 Loading data for BTCUSDT...\n",
      "🔧 Adding timeframe-specific technical indicators...\n",
      "🔧 Converting levels cache index to DatetimeIndex...\n",
      "✅ Loaded levels cache: data\\levels_cache\\BTCUSDT-15m-levels.parquet\n",
      "📊 Shape: 101,000 rows × 9 columns\n",
      "🔄 Recalculating higher timeframe indicators for 15m...\n",
      "Columns in features_df: 50 ['time', 'open', 'high', 'low', 'close', 'volume', 'rsi', 'macd', 'macd_signal', 'macd_hist', 'bb_upper', 'bb_lower', 'bb_position', 'volume_ma20', 'volume_ratio', 'obv', 'volatility', 'atr', 'adx', 'ema5', 'ema9', 'ema13', 'ema20', 'ema21', 'ema50', 'ema200', 'ema9_ema21_cross', 'ema20_ema50_cross', 'stochastic_k', 'stochastic_d', 'vwap', 'levels_json', 'ema20_1h', 'ema50_1h', 'ema200_1h', 'rsi_1h', 'macd_1h', 'macd_hist_1h', 'ema20_D', 'ema50_D', 'macd_hist_D', 'rsi_D', 'ema20_W', 'ema50_W', 'macd_hist_W', 'rsi_W', 'ema20_M', 'ema50_M', 'macd_hist_M', 'rsi_M']\n",
      "\n",
      "🎯 Training Session 1/1\n",
      "------------------------------\n",
      "⚠️ GPU not available, using CPU (training will be slower)\n",
      "🖥️ RL Training Device: cpu\n",
      "\n",
      "🎯 Training PPO agent...\n",
      "🚀 Starting training with proper data split...\n",
      "📊 Train data: 80,800 rows, Eval data: 20,200 rows\n",
      "🔧 Creating training environment with fitted normalizer...\n",
      "🔧 Fitting new normalizer to training data...\n",
      "🔧 Fitting normalizers for 38 features...\n",
      "✅ Fitted 38 normalizers\n",
      "⚡ Pre-normalizing feature data...\n",
      "✅ Pre-normalized 38 features\n",
      "📥 Creating evaluation environment with pre-fitted normalizer...\n",
      "📥 Using provided pre-fitted normalizer\n",
      "⚡ Pre-normalizing feature data...\n",
      "✅ Pre-normalized 38 features\n",
      "🔍 Validating data integrity...\n",
      "ℹ️ Training data NaN summary:\n",
      "   • Features with NaN: 12\n",
      "   • Highest NaN count: ema200 (199 values)\n",
      "   • Cause: Early indicator calculation periods (expected)\n",
      "   • Handling: NaN → neutral values (RSI→50, MACD→0, etc.)\n",
      "✅ All NaN values successfully converted to neutral trading signals\n",
      "🚀 Initializing PPO model on cpu...\n",
      "🎯 Training PPO with integrated evaluation and progress tracking\n",
      "📈 Evaluation every 1,000 timesteps using 10 episodes\n",
      "🎯 Training PPO model for 10,000 timesteps on cpu...\n",
      "⏱️ Progress updates every 1000 timesteps\n",
      "⏹️ Early stopping: 8 evaluations without improvement (threshold: 0.01)\n",
      "============================================================\n",
      "🚀 Starting PPO training...\n",
      "🚀 Training started at 17:08:03\n",
      "📊 Target: 10,000 timesteps\n",
      "============================================================\n",
      "📈 Step 1,000/10,000 (10.0%) | Speed: 326 steps/s | ETA: 00:27 | 🔄 RUNNING\n",
      "Eval num_timesteps=1000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "New best mean reward!\n",
      "📈 Step 2,000/10,000 (20.0%) | Speed: 7 steps/s | ETA: 19:32 | 🔄 RUNNING\n",
      "Eval num_timesteps=2000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 3,000/10,000 (30.0%) | Speed: 5 steps/s | ETA: 23:35 | 🔄 RUNNING\n",
      "Eval num_timesteps=3000, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 4,000/10,000 (40.0%) | Speed: 4 steps/s | ETA: 22:57 | 🔄 RUNNING\n",
      "Eval num_timesteps=4000, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 5,000/10,000 (50.0%) | Speed: 4 steps/s | ETA: 20:41 | 🔄 RUNNING\n",
      "Eval num_timesteps=5000, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 6,000/10,000 (60.0%) | Speed: 4 steps/s | ETA: 17:08 | 🔄 RUNNING\n",
      "Eval num_timesteps=6000, episode_reward=-0.05 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 7,000/10,000 (70.0%) | Speed: 4 steps/s | ETA: 13:14 | 🔄 RUNNING\n",
      "Eval num_timesteps=7000, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 8,000/10,000 (80.0%) | Speed: 4 steps/s | ETA: 08:57 | 🔄 RUNNING\n",
      "Eval num_timesteps=8000, episode_reward=-0.01 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "📈 Step 9,000/10,000 (90.0%) | Speed: 4 steps/s | ETA: 04:33 | 🔄 RUNNING\n",
      "Eval num_timesteps=9000, episode_reward=-0.02 +/- 0.00\n",
      "Episode length: 19528.00 +/- 0.00\n",
      "🛑 Training stopped by early stopping callback\n",
      "============================================================\n",
      "✅ Training completed in 57:07\n",
      "📊 Average speed: 3 steps/s\n",
      "🎯 Final timesteps: 9,000\n",
      "💾 Enhanced training data saved to: models/rl_demo\\enhanced_training_data.json\n",
      "✅ Training completed successfully\n",
      "⏹️ Training stopped early due to no improvement\n",
      "📊 Best reward achieved: 0.0011 at timestep 0\n",
      "📈 Loading best model from evaluation...\n",
      "✅ Model saved to: models/rl_demo\\ppo_trading.zip\n",
      "💾 Saved normalizer to models/rl_demo\\normalizer.pkl\n",
      "✅ Training completed! Basic report:\n",
      "📋 Model saved to: models/rl_demo\n",
      "🎯 Final timesteps: 1,000\n",
      "\n",
      "🔥 RL Agent ready for prediction generation!\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Train the RL Model - Main Training Cell\n",
    "from src.prediction.rl_predictor import RLPredictor\n",
    "print(\"🚀 Starting RL Model Training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "symbol = 'BTCUSDT'\n",
    "dfs = loader.load_data(symbol)\n",
    "features_df = dfs['15m']\n",
    "loop = 1\n",
    " \n",
    "\n",
    "print(\"Columns in features_df:\", len(features_df.columns.tolist()), features_df.columns.tolist())\n",
    "for session in range(1, loop + 1):\n",
    "    print(f\"\\n🎯 Training Session {session}/{loop}\")\n",
    "    print(\"-\" * 30)\n",
    "    # Initialize RL Predictor\n",
    "    rl_predictor = RLPredictor(model_dir='models/rl_demo')\n",
    "\n",
    "    # Train the RL model with default parameters\n",
    "    print(f\"\\n🎯 Training PPO agent...\")\n",
    "    try:\n",
    "        rl_predictor.train(features_df, generate_report=True)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Training failed: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(f\"\\n🔥 RL Agent ready for prediction generation!\")\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a887366",
   "metadata": {},
   "source": [
    "## 📊 Show Training Report\n",
    "\n",
    "After training completes, you can display the comprehensive PPO performance analysis with interactive charts and AI-friendly summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a86a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Generating Training Performance Report\n",
      "==================================================\n",
      "🚀 PPO Training Performance Report\n",
      "============================================================\n",
      "📊 Loaded enhanced training data with trading metrics\n",
      "📊 SESSION OVERVIEW\n",
      "==============================\n",
      "Algorithm: PPO\n",
      "Timesteps: 9,000 / 10,000\n",
      "Evaluations: 0\n",
      "Duration: 57:07\n",
      "Speed: 3 steps/sec\n",
      "Status: ✅ Completed\n",
      "\n",
      "🎯 PPO PERFORMANCE METRICS\n",
      "===================================\n",
      "\n",
      "�🔍 TRAINING STABILITY\n",
      "=========================\n",
      "Speed Stability: Unknown\n",
      "Data Points: 0\n",
      "Progression: Unknown\n",
      "\n",
      "💡 RECOMMENDATIONS\n",
      "====================\n",
      "  📈 Low clip fraction (<0.05) - could increase learning rate for faster learning\n",
      "  📊 Moderate explained variance - value function making progress\n",
      "  🎲 High entropy - model still exploring (good for early training)\n",
      "\n",
      "📋 COPY-FRIENDLY SUMMARY FOR AI ANALYSIS\n",
      "=============================================\n",
      "Training Configuration:\n",
      "- Algorithm: PPO\n",
      "- Timesteps: 9,000\n",
      "- Duration: 3427.8s\n",
      "- Speed: 3 steps/sec\n",
      "- Evaluations: 0\n",
      "\n",
      "Final Metrics:\n",
      "\n",
      "Key Issues/Strengths:\n",
      "- NOTE: Low clip fraction (<0.05) - could increase learning rate for faster learning\n",
      "- MODERATE: Moderate explained variance - value function making progress\n",
      "- INFO: High entropy - model still exploring (good for early training)\n",
      "❌ No step metrics available for charts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'session_overview': {'algorithm': 'PPO',\n",
       "  'total_timesteps': 10000,\n",
       "  'actual_timesteps': 9000,\n",
       "  'duration_seconds': 3427.8327283859253,\n",
       "  'avg_speed': 2.6255656892096537,\n",
       "  'start_time': '2025-10-12 18:05:11',\n",
       "  'end_time': '2025-10-12 18:05:11',\n",
       "  'completed': True,\n",
       "  'total_evaluations': 0},\n",
       " 'performance_metrics': {},\n",
       " 'loss_trends': {},\n",
       " 'training_stability': {'status': 'insufficient_data'},\n",
       " 'trading_performance': {'status': 'no_data'},\n",
       " 'evaluation_progress': {'status': 'no_data'},\n",
       " 'portfolio_analysis': {'status': 'no_data'},\n",
       " 'recommendations': ['📈 Low clip fraction (<0.05) - could increase learning rate for faster learning',\n",
       "  '📊 Moderate explained variance - value function making progress',\n",
       "  '🎲 High entropy - model still exploring (good for early training)']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Comprehensive Training Report\n",
    "# This shows PPO performance metrics, interactive charts, and AI-friendly analysis\n",
    "\n",
    "from src.reporting.model_training_report import ModelTrainingReport\n",
    "\n",
    "\n",
    "print(\"📊 Generating Training Performance Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "report = ModelTrainingReport()\n",
    "# Show the training report with charts and analysis\n",
    "# This reads the training data captured by the callback during training\n",
    "report.show_training_report()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
